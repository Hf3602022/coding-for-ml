{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c8e24b-064a-41b3-b3d5-1bef5e9e1ba0",
   "metadata": {},
   "source": [
    "# Stroke data wrangling\n",
    "\n",
    "Thrombolysis is a clot busting treatment for people suffering from a ischemic stroke: where a blood clot is preventing blood flow to the brain causing it to die. In England, national data on thrombolysis treatment at individual hospitals strokes is collected and stored centrally.   This exercise will make use of synthetic dataset based on the real data used in \n",
    "\n",
    "**Allen M, Pearn K, Monks T, Bray BD, Everson R, Salmon A, James M, Stein K (2019). *Can clinical audits be enhanced by pathway simulation and machine learning? an example from the acute stroke pathway*. BMJ Open, 9(9).**\n",
    "\n",
    "The data you are presented with in a data science or machine learning study nearly always requires a preprocessing step.  This may include wrangling the data into a format suitable for machine learning, understanding (and perhaps imputing) missing values and cleaning/creation of features.  In this exercise you will need to wrangle the stroke thrombolysis dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0601e-891a-49da-8e54-e3eccfd87e0c",
   "metadata": {},
   "source": [
    "## Exercise 1: Read and initial look\n",
    "\n",
    "The dataset is held in `synth_lysis.csv`.\n",
    "\n",
    "**Task**:\n",
    "* Read the stroke thrombolysis dataset into a `pandas.DataFrame`\n",
    "* Use appropriate `pandas` and `DataFrame` methods and functions to gain an overview of the dataset and the features it contains.\n",
    "\n",
    "**Hints**:\n",
    "* You might look at:\n",
    "    * Size of the dataset, feature (field/variable) naming, data types, missing data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cf4aaf-af48-4201-9bed-15b8db2de05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_URL = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "            + 'hpdm139-datasets/main/synth_lysis.csv'\n",
    "\n",
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a87e5f-df8a-48a6-92be-39cc11e90643",
   "metadata": {},
   "source": [
    "## Exercise 2: Clean up the feature names\n",
    "\n",
    "The naming of features in this dataset is inconsistent.  There is mixed capitalisation and use of spaces in variable names. A feature is called `label` which is not particularly useful.  This is the label indicating if a patient recieved thrombolysis or not.  \n",
    "\n",
    "**Task**:\n",
    "* convert all feature names to lower case \n",
    "* remove all spaces from names\n",
    "* rename `label` to `treated`.\n",
    "\n",
    "**Hints**:\n",
    "* Assuming your `DataFrame` is called `df` you can get and set the column names using `df.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44442dfd-94f3-4139-9c1c-475c117982b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3bae5-26fd-43f4-8ecc-06b2fb0fbfa0",
   "metadata": {},
   "source": [
    "## Exercise 3: Create a pre-processing function\n",
    "\n",
    "It is useful to cleanly organise your data wrangling code.  Let's create a skeleton of one now before we get into any detailed wrangling.\n",
    "\n",
    "There are a number of ways we might do this from functions, classes to specialist libraries such as [`pyjanitor`](https://pyjanitor.readthedocs.io/index.html#).  Here we will prefer our own simple functions. \n",
    "\n",
    "**Task**:\n",
    "* Create a function `wrangle_lysis`\n",
    "* The function should accept a `str` parameter specifying the data url or directory path and filename of our thrombolysis data set.\n",
    "* For now set the function up to read in the data (from exercise 1) and clean the feature headers (exercise 2). \n",
    "* The function should return a `pd.DataFrame` containing the stroke thrombolysis data.\n",
    "\n",
    "**Hints**:\n",
    "* Get into the habit of writing a simple docstring for your functions.\n",
    "\n",
    "> This function will come in handy for the later exercises where you may make mistakes and muck up your nicely cleaned datasets!  You can just reload and process them with one command after this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f726fd-bef5-4f9c-a3b8-f48c4cd4222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5022c1c-9900-4bfe-8341-62bfeb3dc501",
   "metadata": {},
   "source": [
    "## Exercise 4: Explore categorical features\n",
    "\n",
    "A number of features are categorical.  For example, `male` contains two values `Y` (the patient is male) and `N` (the patient is not male).\n",
    "\n",
    "**Task**:\n",
    "* List the categories contained in the following fields:\n",
    "\n",
    "```python\n",
    "fields = ['hospital', 'male', 'severity', 'stroke_type', 'treated']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b1e7e0-db8f-4939-b41f-326fcf83fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4129c-0b46-45a8-818c-18d28c95ff64",
   "metadata": {},
   "source": [
    "## Exercise 5: Encode categorical fields with 2 levels \n",
    "\n",
    "In exercise 4, you should find that the `male` and `treated` columns have two levels (yes and no). If we take `male` as an example we can encode it as a single feature as follows:\n",
    "\n",
    "$$ x_i = \\Bigg\\{ \\begin{matrix} 1 & \\mbox{if }i \\mbox{th person is male}\n",
    "\\\\  0 & \\mbox{if }i \\mbox{th person is female}\\end{matrix} $$\n",
    "\n",
    "> Note: we will deal with `stroke_type` which has two levels and missing data in exercise 6.\n",
    "\n",
    "**Task**:\n",
    "* Encode `male` and `treated` to be binary 0/1 fields.\n",
    "* Update `wrangle_lysis` to include this code.\n",
    "\n",
    "**Hints**\n",
    "* [Try the `pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function. \n",
    "* Remember that you only need one variable when a categorical field has two values. You can use the `drop_first=True` to keep only one variable (just make sure its the right one!).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261cd1ba-6518-4a35-ae7a-8e73a1f74a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b93e7-3664-4466-8c2d-b18e4e95246c",
   "metadata": {},
   "source": [
    "## Exercise 6: Encoding fields with > 2 categories\n",
    "\n",
    "The process to encode features with more than category is almost identical to that used in exercise 6.  For example the `hospital` field contains 8 unique values.  There are now two options.  \n",
    "\n",
    "1. encode as 7 dummy variables where all 0's indicates hospital 1.\n",
    "2. use a one-hot encoding and include 8 variables.  The additional degree of freedom allows you to encode missing data as all zeros. \n",
    "\n",
    "Note that some methods such as ordinary least squares regression require you to take approach one.  More flexible machine learning approaches can handle approach 2.  Here we will make use of approach 2.\n",
    "\n",
    "**Task**:\n",
    "* Use a one-hot encoding on the `hospital` column.\n",
    "* Use a one-hot encoding on the `stroke_type` column. You should prefix the new encoded columns with `stroke_type_`. I.e. you will have two columns `stroke_type_clot` and `stroke_type_bleed`.\n",
    "\n",
    "**Hints**:\n",
    "* One hot encoding is just the same as calling `pd.get_dummies`, but we set `drop_first=False`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e27fc42-c09c-4353-9eaa-55e85919fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
