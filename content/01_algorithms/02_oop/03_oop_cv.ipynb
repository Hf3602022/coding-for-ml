{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ffbc7-87be-4c5d-9c40-4c343aca69cb",
   "metadata": {},
   "source": [
    "# Case study: Cross-validation\n",
    "\n",
    "In supervised learning studies we distinguish between the training and test error rates. The test error rate refers to the average performance of a model when predicting a new observation (data that was not used in the training of the model).  A useful model is one that can accurately predict new observations!\n",
    "\n",
    "An issue in real ML studies is that data are expensive to collect and often a health data scientist doesn't have as much validation data as they would ideally like for estimating the test error rate.  Cross-validation is a general term to describe a set of statistical methods for efficiently splitting a dataset in order to estimating the test error of a model.\n",
    "\n",
    "In the case study we will explore creating two classes for cross validation in machine learning: **Leave-One-Out Cross-Validation** and **K-Fold Cross Validation.**\n",
    "\n",
    "> If you are interested to read further on cross validation I recommend the excellent: **An introduction to statistical learning (with application sin R)** by James, Witten, Hastie and Tibshirani. \n",
    "\n",
    "\n",
    "> Disclaimer: In a real machine learning study there is no doubt that you would implement these classes using a `numpy` array.  In practice I would therefore implement these classes slightly differently. We will cover `numpy `in the next chapter.  Another bullet proof option, that requires no implementation, is to use the `sklearn.model_selection` namespace.\n",
    "\n",
    "We'll begin by creating each class independently.  Then we'll work on our OOP design credentials by extracting what can be encapsulated into a common baseclass.  Finally we will take a short look at what is meant by an Abstract class and how this is implemented in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8748cb04-4f8b-4e07-8e15-f14cbfef4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118be9f9-f62b-4392-89b5-9dca7467b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leave one out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b07b8b18-c4a7-41e4-9500-934cb4f2a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOOCV:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'LOOCV()'\n",
    "    \n",
    "    # generator\n",
    "    def split(self, X, y):\n",
    "        for test_index in range(len(X)):\n",
    "        \n",
    "            # training data indexes\n",
    "            train_X = X[:test_index] + X[test_index + 1:]\n",
    "            train_y = y[:test_index] + y[test_index + 1:]\n",
    "            \n",
    "            # test data\n",
    "            test_X, test_y = X[test_index], y[test_index]\n",
    "            \n",
    "            yield train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7a459033-c7c5-41fb-b8d5-8b705376c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldCV:\n",
    "    def __init__(self, k=5, shuffle=False, random_seed=None):\n",
    "        self.k = k\n",
    "        self.random_seed = random_seed\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'KFoldCV(k={self.k})'\n",
    "    \n",
    "    # generator\n",
    "    def split(self, X, y):\n",
    "        \n",
    "        # store the indexes of each element - its these that get shuffled.\n",
    "        idx = [i for i in range(len(X))]\n",
    "        if self.shuffle:\n",
    "            random.seed(self.random_seed)\n",
    "            random.shuffle(indicies)\n",
    "        \n",
    "        # length of k - 1 splits... final split continues to end.\n",
    "        split_len = int(len(X) / (self.k))\n",
    "\n",
    "        for test_idx in range(0, len(X), split_len):\n",
    "        \n",
    "            # create k - 1 training folds for X \n",
    "            train_X = self._fold_training_data(X, idx, test_idx, split_len)\n",
    "            # X test data for fold\n",
    "            test_X = [X[idx[i]] for i in range(test_idx, test_idx + split_len)]\n",
    "            \n",
    "            # create k - 1 training segments for y\n",
    "            train_y = self._fold_training_data(y, idx, test_idx, split_len)\n",
    "            # y test data fold\n",
    "            test_y = [y[idx[i]] for i in range(test_idx, test_idx + split_len)]\n",
    "            \n",
    "            yield train_X, test_X, train_y, test_y\n",
    "            \n",
    "        \n",
    "    def _fold_training_data(self, data, idx, test_idx, split_len):\n",
    "        '''\n",
    "        create training segments for X or y\n",
    "        '''\n",
    "        train_seg1 = [data[idx[i]] for i in range(test_idx)]\n",
    "        train_seg2 = [data[idx[i]] for i in range((test_idx + split_len), \n",
    "                                                 len(data))]                                \n",
    "        return train_seg1 + train_seg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6a70aef4-7b0f-4117-973a-44e1aba04c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data \n",
    "# this is three data points.  each data point has two features.\n",
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "y = [[1], [2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "68d8a61c-67f2-4443-80cc-7082ae1a7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_classification(n=10, shuffle=False, random_seed=None):\n",
    "    '''\n",
    "    Generates a simple random synthetic dataset.\n",
    "    \n",
    "    X data is a sequence 1 to n \n",
    "    y data is 0 or 1 weighted roughly 50/50.\n",
    "    '''\n",
    "    X = [i for i in range(1, n+1)]\n",
    "    y = ([1] * (n // 2)) + ([0] * ((n // 2) + (n % 2)))\n",
    "    \n",
    "    if shuffle: \n",
    "        for lst in [X, y]:\n",
    "            random.seed(random_seed)\n",
    "            random.shuffle(lst)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "adcf9d26-86f1-402a-b90b-84826647ddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train:\tX:[3, 4, 5, 6, 7, 8, 9, 10], y:[1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test:\tX:[1, 2], y:[1, 1]\n",
      "Fold 1:\n",
      "Train:\tX:[1, 2, 5, 6, 7, 8, 9, 10], y:[1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test:\tX:[3, 4], y:[1, 1]\n",
      "Fold 2:\n",
      "Train:\tX:[1, 2, 3, 4, 7, 8, 9, 10], y:[1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Test:\tX:[5, 6], y:[1, 0]\n",
      "Fold 3:\n",
      "Train:\tX:[1, 2, 3, 4, 5, 6, 9, 10], y:[1, 1, 1, 1, 1, 0, 0, 0]\n",
      "Test:\tX:[7, 8], y:[0, 0]\n",
      "Fold 4:\n",
      "Train:\tX:[1, 2, 3, 4, 5, 6, 7, 8], y:[1, 1, 1, 1, 1, 0, 0, 0]\n",
      "Test:\tX:[9, 10], y:[0, 0]\n"
     ]
    }
   ],
   "source": [
    "X, y = synthetic_classification()\n",
    "\n",
    "cv = KFoldCV(k=5)\n",
    "i = 0\n",
    "for train_X, test_X, train_y, test_y in cv.split(X, y):\n",
    "    print(f'Fold {i}:\\nTrain:\\tX:{train_X}, y:{train_y}')\n",
    "    print(f'Test:\\tX:{test_X}, y:{test_y}')\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "07a7a3a5-629c-4ec6-b370-e227357e44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = synthetic_classification(random_seed=101)\n",
    "cv = LOOCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "073f71cb-df58-4fc7-9917-61cd4c5d66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFold:\n",
    "    def __init__(self, k=5, shuffle=False, random_seed=None):\n",
    "        self.k = k\n",
    "        self.shuffle = shuffle\n",
    "        self.rng = np.random.default_rng(random_seed)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        rep = f'KFoldCV(k={self.k}, shuffle={self.shuffle},' \\\n",
    "                + f'random_seed={self.random_seed})'\n",
    "\n",
    "    def split(self, X, y):\n",
    "        \n",
    "        # store the indexes of each element - its these that get shuffled.\n",
    "        if self.shuffle:\n",
    "            idx = self.rng.integers(0, len(X), size=len(X))\n",
    "        else:\n",
    "            idx = np.arange(len(X))\n",
    "        \n",
    "        # length of k - 1 splits... final split continues to end.\n",
    "        split_len = int(len(X) / (self.k))\n",
    "\n",
    "        for test_idx in range(0, len(X), split_len):\n",
    "        \n",
    "            # create k - 1 training folds for X \n",
    "            train_X = self._fold_training_data(X, idx, test_idx, split_len)\n",
    "            # X test data for fold\n",
    "            test_X = [X[idx[i]] for i in range(test_idx, test_idx + split_len)]\n",
    "            \n",
    "            # create k - 1 training segments for y\n",
    "            train_y = self._fold_training_data(y, idx, test_idx, split_len)\n",
    "            # y test data fold\n",
    "            test_y = [y[idx[i]] for i in range(test_idx, test_idx + split_len)]\n",
    "            \n",
    "            yield train_X, test_X, train_y, test_y\n",
    "            \n",
    "        \n",
    "    def _fold_training_data(self, data, idx, test_idx, split_len):\n",
    "        '''\n",
    "        create training segments for X or y\n",
    "        '''\n",
    "        train_seg1 = [data[idx[i]] for i in range(test_idx)]\n",
    "        train_seg2 = [data[idx[i]] for i in range((test_idx + split_len), \n",
    "                                                 len(data))]                                \n",
    "        return train_seg1 + train_seg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fc2ce6a7-1355-4972-ab9f-9b72960e30f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_393368/89627821.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_idx' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.arange(1, 11)\n",
    "idx = np.array([5, 6, 7, 8, 9, 0, 1, 2, 3, 4])\n",
    "X[idx[:test_idx]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "00fcc9b9-d6c8-468e-b5cc-7a3c59ce1b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
      "y:[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Fold 1:\n",
      "Train: [2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test:1, 1\n",
      "Fold 2:\n",
      "Train: [1, 3, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test:2, 1\n",
      "Fold 3:\n",
      "Train: [1, 2, 4, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test:3, 1\n",
      "Fold 4:\n",
      "Train: [1, 2, 3, 5, 6, 7, 8, 9, 10], [1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test:4, 1\n",
      "Fold 5:\n",
      "Train: [1, 2, 3, 4, 6, 7, 8, 9, 10], [1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test:5, 1\n",
      "Fold 6:\n",
      "Train: [1, 2, 3, 4, 5, 7, 8, 9, 10], [1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Test:6, 0\n",
      "Fold 7:\n",
      "Train: [1, 2, 3, 4, 5, 6, 8, 9, 10], [1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Test:7, 0\n",
      "Fold 8:\n",
      "Train: [1, 2, 3, 4, 5, 6, 7, 9, 10], [1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Test:8, 0\n",
      "Fold 9:\n",
      "Train: [1, 2, 3, 4, 5, 6, 7, 8, 10], [1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Test:9, 0\n",
      "Fold 10:\n",
      "Train: [1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Test:10, 0\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(f'X:{X}, \\ny:{y}')\n",
    "for train_X, train_y, test_X, test_y in cv.split(X, y):\n",
    "    print(f'Fold {i}:')\n",
    "    print(f'Train: {train_X}, {train_y}')\n",
    "    print(f'Test:{test_X}, {test_y}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f941072a-5b18-40dc-a220-e3af77fd3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c639ed7-d062-4370-904c-a6811c87ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LeaveOneOut()\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d938469c-7ed5-4c08-a7a3-d9a3b6d91e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside\n",
      "[[3, 4], [5, 6], [1, 2]]\n",
      "outside\n",
      "[[1, 2], [3, 4], [5, 6]]\n"
     ]
    }
   ],
   "source": [
    "def test_change(X):\n",
    "    x2 = copy.copy(X)\n",
    "    random.shuffle(x2)\n",
    "    print('inside')\n",
    "    print(x2)\n",
    "    \n",
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "test_change(X)\n",
    "\n",
    "print('outside')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab43c6c-8a8d-4850-86b4-76e042d35602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
