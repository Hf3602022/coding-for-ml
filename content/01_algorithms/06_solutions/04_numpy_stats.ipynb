{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d83a5b-d0dc-4613-9a29-b93714d6d13b",
   "metadata": {},
   "source": [
    "# Statistical procedures in `numpy`\n",
    "\n",
    "The following exercises test some of your new `numpy` skills on some basic statistical problems.  In some cases there is more than one solution.  Feel free to experiment with different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf809fb-293a-4590-9faf-2196e82676b1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6087f2d-560a-4990-9b39-6e8ad916c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# you will need requests and io to download the data and load into a numpy array\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b9512-54c1-4375-afb7-897fe10f96e4",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "In this exercise, you will use `numpy` to generate a random variable following a standard normal distribution.  You will then use the statistical functions built into numpy to analyse the distribution of the variable.\n",
    "\n",
    "**Task**:\n",
    "* Take 10,000 samples from the standard normal distribution\n",
    "* Create a function called `basic_descriptives` that returns the mean, stdev, and 1st/99th percentiles of a numpy array parameter.\n",
    "* Call your function and printout the results.\n",
    "\n",
    "**Hints**:\n",
    "* You can assume the numpy array passed to the function contains float data or you could check and raise an exception.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33864505-a92a-482a-afb1-da56675ec7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99af2492-b97d-46f4-88cf-beb2f0556dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# example solution\n",
    "\n",
    "SAMPLE_SIZE = 10_000\n",
    "\n",
    "# create a random number generator\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# generate numpy array of size SAMPLE_SIZE using standard normal\n",
    "samples = rng.normal(size=SAMPLE_SIZE)\n",
    "print(type(samples))\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ea38f3-157a-4008-9ad4-97402b0b068d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.01024987541401165, 1.006285768537041, -2.3738111979173713, 2.3558409670159173)\n"
     ]
    }
   ],
   "source": [
    "def basic_descriptives(data):\n",
    "    \"\"\"\n",
    "    Returns mean, stdev, and 1st and 99th percentile of a 1D numpy.ndarray\n",
    "    \n",
    "    Assumes `data` is numpy array of floats.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    data: numpy.ndarray \n",
    "        numeric data to analyse\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    (float, float, float, float)\n",
    "    \"\"\"\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    per_1st = np.percentile(data, 1) \n",
    "    per_99th = np.percentile(data, 99)\n",
    "    \n",
    "    return mean, std, per_1st, per_99th\n",
    "\n",
    "\n",
    "results = basic_descriptives(samples)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da9988-a9d5-4b56-acd8-27a6f64502b2",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Reuse the data generated in exercise 1.  You are going to analyse the tails of the distribution you generated.\n",
    "\n",
    "**Task:**\n",
    "* Select only the samples that have a value greater than or equal to +1.96 and less than or equal to -1.96\n",
    "* Determine the proportion of data that falls into these tails.\n",
    "* Are these proportions what you expect for the standard normal distribution?\n",
    "\n",
    "**Hints**:\n",
    "* You may want to create one or two general functions so that you can use to vary the cut-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9100fb79-0b9f-4f94-9c94-bc87c07316a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e49bb5-8832-49fa-879b-659f90b374e2",
   "metadata": {},
   "source": [
    "**Example solution:**\n",
    "\n",
    "It is very simple to work with `numpy` arrays containing numeric data. For example if we wanted to find all of our samples that are greater than or equal to +1.96 we use:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea9595c-26bf-4c14-ae90-fde8e835b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "<class 'numpy.ndarray'>\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "# result is a array of bools\n",
    "result = samples >= 1.96\n",
    "\n",
    "print(result.shape)\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7a9f8-85f6-4563-b8c4-b6d2dfe41535",
   "metadata": {},
   "source": [
    "The code returns a new numpy.ndarray that contains boolean (True/False) values. The value at array index i is True if the corresponding value at index i in array data is >= 2.3 and False otherwise. If we had used a python List we would have needed to loop through all of list items and perform the check ourselves.\n",
    "\n",
    "Let's create some generalised functions to return the probabilities that a value is greater or less than a user specified value in our data set.\n",
    "\n",
    "To do that we need to know that\n",
    "\n",
    "```python\n",
    "False == 0\n",
    "True == 1\n",
    "```\n",
    "\n",
    "Therefore we can take the sum of our boolean array to find out how many array elements are greater or less than a user specified values. i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3aa795-3c13-4d3a-93f1-78313006ffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(samples >= 1.96).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da56de66-c3cb-4772-b822-7295380ff054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0257 0.0257\n",
      "0.9486\n"
     ]
    }
   ],
   "source": [
    "def prob_great_than_or_equal_to(data, x):\n",
    "    '''\n",
    "    Return the proportion of the dataset that is greater than or equal to x\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data: numpy.ndarray \n",
    "        numeric data to analyse\n",
    "    x: float\n",
    "        Lower cut-off. \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "    '''\n",
    "    return (data >= x).sum()/data.shape[0]\n",
    "\n",
    "\n",
    "def prob_less_than_or_equal_to(data, x):\n",
    "    '''\n",
    "    Return the proportion of the dataset that is less than or equal to x\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data: numpy.ndarray \n",
    "        numeric data to analyse\n",
    "    x: float\n",
    "        Upper cut-off. \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "    '''\n",
    "    return (data <= x).sum()/data.shape[0]\n",
    "\n",
    "p1 = prob_great_than_or_equal_to(samples, 1.96)\n",
    "p2 = prob_less_than_or_equal_to(samples, -1.96)\n",
    "\n",
    "print(p1, p2)\n",
    "print(1 - (p1+p2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831e251-dd73-40d2-8eb9-94d790675dd0",
   "metadata": {},
   "source": [
    "Our test of these functions shows use that around 95% of data lie between points -1.96 and +1.96 (which again we would expect with the standard normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52614ef3-6d70-4cd8-898b-ec86e6b9aad0",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "    \n",
    "Assume you have the data \n",
    "\n",
    "```python\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "```        \n",
    "* The 20% Winsorized mean of `data` is calculated on a modified data set where the top and bottom 10% of values are replaced by the 10th and 90th percentiles.  \n",
    "* In this case the 10th percentile = 2 and the 90th = 10.  Therefore the winsorized dataset is:\n",
    "\n",
    "```python\n",
    "win_data = [2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10]\n",
    "\n",
    "win_mean = win_data.mean()\n",
    "```\n",
    "\n",
    "**Task:**\n",
    "* Write a function `winsorize(data, cut_off=0.1)`\n",
    "* The function must modify `data` (type `np.ndarray`) so that is it is winsorized.  \n",
    "* A cut_off = 0.1 specifies that the function uses the 10th and 90th percentiles as cut-offs\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "* There are multiple ways to solve this problem\n",
    "    * You could use a `for` loop\n",
    "    * You could create a function that is vectorized using `np.vectorize()`\n",
    "    * You could use `np.where()` and fancy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e60b93-85ff-4b8f-a6db-23685e5ea29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b4dfa5-904e-4fcc-8ec0-3f68aaee081e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  2  3  4  5  6  7  8  9 10 10]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Exercise 3\n",
    "# Solution 1: Using a `for` loop\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def winsorize_loop(data, cut_off = 0.1):\n",
    "    low = np.percentile(data, cut_off * 100)\n",
    "    high = np.percentile(data, (1-cut_off) * 100)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i] > high:\n",
    "            data[i] = high\n",
    "        elif data[i] < low:\n",
    "            data[i] = low\n",
    "\n",
    "            \n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "\n",
    "winsorize_loop(data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "368e7902-cf5b-48ca-afa8-8daab6f7aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  3.  4.  5.  6.  7.  8.  9. 10. 10.]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Exercise 3\n",
    "# Solution 2: Using a vectorized functioon\n",
    "# =============================================================================\n",
    "\n",
    "def winsorize_to_vectorize(to_test, low, high):\n",
    "\n",
    "    if to_test > high:\n",
    "        return high\n",
    "    elif to_test < low:\n",
    "        return low\n",
    "    else:\n",
    "        return to_test\n",
    "    \n",
    "def winsorize_limits(data, cut_off):\n",
    "    low = np.percentile(data, cut_off * 100)\n",
    "    high = np.percentile(data, (1-cut_off) * 100)\n",
    "    \n",
    "    return low, high\n",
    "    \n",
    "    \n",
    "v_winsorise = np.vectorize(winsorize_to_vectorize)    \n",
    "\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "low, high = winsorize_limits(data, 0.1)\n",
    "w_data = v_winsorise(data, low, high)\n",
    "\n",
    "print(w_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6cff64-fc6f-413f-ab0f-396325ff709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  2  3  4  5  6  7  8  9 10 10]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Exercise 3\n",
    "# Solution 3: Using np.where()\n",
    "# =============================================================================\n",
    "\n",
    "def winsorize(data, cut_off = 0.1):\n",
    "    low = np.percentile(data, cut_off * 100)\n",
    "    high = np.percentile(data, (1-cut_off) * 100)\n",
    "       \n",
    "    data[np.where(data < low)] = low\n",
    "    data[np.where(data > high)] = high\n",
    "    \n",
    "\n",
    "#data = np.random.normal(10, 1, 100)\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "\n",
    "\n",
    "winsorize(data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb6b9bd0-ee0e-41c0-a460-4297ffac5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance testing of solutions\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f8979d-0894-4033-908e-bcb8facc91cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 µs ± 1.78 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit winsorize_loop(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "792119f1-7482-49cc-93b2-d87c66457196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset data\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7a9553-f3c8-4bff-a4d9-174fccafc02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 µs ± 3.86 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "low, high = winsorize_limits(data, 0.1)\n",
    "w_data = v_winsorise(data, low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ae23739-6a0d-4e1d-b30f-7c3bf766586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34baf826-ae60-472c-b5ed-145e86902d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 µs ± 2.22 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit winsorize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6616ca2-9bd4-4e5d-973a-fa1fcd8e7995",
   "metadata": {},
   "source": [
    "### Exercise 4: \n",
    "\n",
    "**Simple linear regression using data in `numpy` arrays**\n",
    "    \n",
    "In this example we will load two `numpy arrays from file and conduct a simple linear regression.  The method of Ordinary Least Squares is used to fit a linear model (think $y = \\beta_1 x + \\beta_0 + \\epsilon $ ) to some data stored in numpy arrays.\n",
    "\n",
    "We have two datasets:\n",
    "\n",
    "* `breach.csv`: monthly totals of people waiting FOUR or more hours in English emergency departments\n",
    "* `dtocs.csv`: monthly total of the number of people waiting to be discharged (leave) hospial and go home or transfer to another form of healthcare.  \n",
    "\n",
    "You are going to (VERY naively) assess the relationship between these two variables.  For the purposes of this exercise we are going to ignore that these two datasets are time-series data.\n",
    "\n",
    "The library you will use to conduct linear regression is `statsmodels.api`\n",
    "You will use the class `OLS` which accepts two keyword arguments: y and x\n",
    "\n",
    "Once you have conducted the analysis you will print the results summary.\n",
    "\n",
    "**Task**:\n",
    "* Import `statsmodels.api`\n",
    "* Load the dtoc and breaches datasets\n",
    "* Treating breaches as the dependent variable and dtocs as the independent variable perform the regression.\n",
    "* What is the $R^2$ of your (naive) model?\n",
    "\n",
    "**Hints:**\n",
    "* The columns of data in the two files have a header (the first line is a string).  You will need to remove that before you can create a numpy array.  Take a look at the options in `np.genfromtxt()`\n",
    "* Your model will need an **intercept**.  This is not automatically added in `statsmodels`.  To do this you need to call `statsmodels.api.add_constant(X)`.  There is a worked example in the statsmodels [documentation](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html?highlight=ols#statsmodels.regression.linear_model.OLS). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db26c43f-3e37-4b7d-9be6-77a365d533db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statsmodels contains the OLS class you will use\n",
    "import statsmodels.api as sm\n",
    "\n",
    "RESPONSE_SUCCESS = 200\n",
    "DTOC_URL = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "                + 'hpdm139-datasets/main/dtocs.csv'\n",
    "BREACH_URL = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "                + 'hpdm139-datasets/main/breach.csv'\n",
    "\n",
    "def download_datasets(url):\n",
    "    '''\n",
    "    Downloads the dtoc and breaches datasets to your local machine\n",
    "    \n",
    "    '''\n",
    "    response = requests.get(DTOC_URL)\n",
    "    if response.status_code == RESPONSE_SUCCESS:\n",
    "        # write the file\n",
    "        with open(\"dtocs.csv\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "            print('success: dtocs.csv downloaded.')\n",
    "    else:\n",
    "        print('connection error for dtocs')\n",
    "    \n",
    "    response = requests.get(BREACH_URL)\n",
    "    if response.status_code == RESPONSE_SUCCESS:\n",
    "        # write the file\n",
    "        with open(\"breach.csv\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "            print('success: breach.csv downloaded.')\n",
    "    else:\n",
    "        print('connection error for dtocs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "165cb9eb-4230-4286-aa38-fbc83d0df2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: dtocs.csv downloaded.\n",
      "success: breach.csv downloaded.\n"
     ]
    }
   ],
   "source": [
    "download_datasets(DTOC_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e07dca1-5686-42e3-8387-e718779174bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1144ed31-fbf1-4a5d-9271-99fbd4a775cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.714\n",
      "Model:                            OLS   Adj. R-squared:                  0.710\n",
      "Method:                 Least Squares   F-statistic:                     194.6\n",
      "Date:                Thu, 14 Oct 2021   Prob (F-statistic):           6.80e-23\n",
      "Time:                        17:21:39   Log-Likelihood:                -945.02\n",
      "No. Observations:                  80   AIC:                             1894.\n",
      "Df Residuals:                      78   BIC:                             1899.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.633e+05      2e+04     -8.178      0.000   -2.03e+05   -1.24e+05\n",
      "x1            57.7282      4.138     13.950      0.000      49.489      65.967\n",
      "==============================================================================\n",
      "Omnibus:                       11.472   Durbin-Watson:                   0.888\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               16.361\n",
      "Skew:                           0.591   Prob(JB):                     0.000280\n",
      "Kurtosis:                       4.874   Cond. No.                     2.61e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.61e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#OLS functionality is in statsmodels\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "def load_dtoc_dataset():\n",
    "    '''\n",
    "    Loads the breach and dtoc data sets into memory\n",
    "    Returns a tuple of numpy.ndarrays representing\n",
    "    breach and dtoc dataset respectively.\n",
    "    '''    \n",
    "    # note we use skip_header because the dataset has column descriptors\n",
    "    dtoc = np.genfromtxt('dtocs.csv', skip_header=1)  \n",
    "    breach = np.genfromtxt('breach.csv', skip_header=1)\n",
    "    return breach, dtoc\n",
    "    \n",
    "breach, dtoc = load_dtoc_dataset()\n",
    "\n",
    "###### regression code ########\n",
    "\n",
    "# add an intercept term to the model\n",
    "dtoc = sm.add_constant(dtoc) \n",
    "model = sm.OLS(breach, dtoc)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f757da-2ebe-419d-912f-397b26fb0ada",
   "metadata": {},
   "source": [
    "## Exercise 5:\n",
    "\n",
    "**Preprocessing data to detrend a timeseries**\n",
    "\n",
    "In exercise 5, we conducted a simple linear regression to assess the relationship between two variables.  Our initial analysis is problematic because both variables are time series and contain autocorrelation and trend.  This means that we violate some of the assumptions of ordinary least squares regression and our estimates of the relationship are likely to be incorrect.\n",
    "\n",
    "In practice, we would pre-process the data in the `numpy` arrays before conducting the regression.  A simple way to do this is to take the first difference of the time series. If $Y_t$ represents the value of the time series at time $t$ then the first difference is equal to:\n",
    "\n",
    "$$Y_t = Y_{t+1} - Y_t$$ \n",
    "\n",
    "**Tip**:  If an array $a$ has length $n$ then an array of the first differences of $a$ is $n-1$\n",
    "\n",
    "**Task**:\n",
    "\n",
    "* Copy your solution code for exercise 4\n",
    "* Modify the code to take the first difference of the `breach` and `dtoc` arrays\n",
    "* Conduct the regression analysis using the first differences (detrended data)\n",
    "* Look at the new $R^2$.  Is there still strong evidence of a relationship?\n",
    "\n",
    "**Hints**:\n",
    "* If you have an array `data` then to take the first difference of the array using:\n",
    "\n",
    "```python\n",
    "differenced = np.diff(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6f8b940-76cb-453d-8441-111ec7a8c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.035\n",
      "Model:                            OLS   Adj. R-squared:                  0.022\n",
      "Method:                 Least Squares   F-statistic:                     2.775\n",
      "Date:                Thu, 14 Oct 2021   Prob (F-statistic):             0.0998\n",
      "Time:                        17:21:39   Log-Likelihood:                -901.09\n",
      "No. Observations:                  79   AIC:                             1806.\n",
      "Df Residuals:                      77   BIC:                             1811.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       2417.0761   2484.505      0.973      0.334   -2530.206    7364.358\n",
      "x1           -13.3144      7.992     -1.666      0.100     -29.229       2.600\n",
      "==============================================================================\n",
      "Omnibus:                       16.746   Durbin-Watson:                   2.174\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.038\n",
      "Skew:                          -0.640   Prob(JB):                     3.33e-09\n",
      "Kurtosis:                       6.197   Cond. No.                         312.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Example solution: Use numpy built-in function np.diff()\n",
    "\n",
    "def load_dtoc_dataset():\n",
    "    '''\n",
    "    Loads the breach and dtoc data sets into memory\n",
    "    Returns a tuple of numpy.ndarrays representing\n",
    "    breach and dtoc dataset respectively.\n",
    "    '''    \n",
    "    # note we use skip_header because the dataset has column descriptors\n",
    "    dtoc = np.genfromtxt('dtocs.csv', skip_header=1)  \n",
    "    breach = np.genfromtxt('breach.csv', skip_header=1)\n",
    "    return breach, dtoc\n",
    "\n",
    "\n",
    "def dtoc_regression(breach, dtoc):\n",
    "    '''\n",
    "    Regression analysis for dtocs\n",
    "    and breaches\n",
    "    \n",
    "    Keyword arguments:\n",
    "    breach - dependent variable\n",
    "    dtoc - independent variable\n",
    "    '''\n",
    "    dtoc = sm.add_constant(dtoc) # an intercept term to the model\n",
    "    model = sm.OLS(breach, dtoc)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "    \n",
    "breach, dtoc = load_dtoc_dataset()\n",
    "\n",
    "# difference the code using np.diff \n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.diff.html\n",
    "d_breach = np.diff(breach)\n",
    "d_dtoc = np.diff(dtoc)\n",
    "\n",
    "dtoc_regression(d_breach, d_dtoc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
