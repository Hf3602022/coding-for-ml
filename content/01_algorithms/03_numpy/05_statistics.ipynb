{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad5cfc6-b300-42a8-8453-0ce697af2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcab5fc-967f-4f4c-956a-ab99ff4893f0",
   "metadata": {},
   "source": [
    "# Statistical procedures\n",
    "\n",
    "A substantial proportion of real world applications in computational modelling require statistical procedures. `numpy` provides a wide variety of efficient statistical functions for you to employ on an array.  This section will explore the (simple and) commonly used functions that you can embed into your models and use for practical statistical analysis.  At the end of the section I'll tell a cautionary tale about blind use of `numpy` statistical procedures versus using a well design algorithm.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> We will explore statistical programming for health data science in a lot more detail in Part 2 using `pandas` and other important libraries.  It is well worth learning `numpy` capabilities, however, as converting from a `np.ndarray` to a `pandas.DataFrame` during a computational procedure can be expensive. </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25845106-20f1-4c9f-bd0c-2e690370bada",
   "metadata": {},
   "source": [
    "## Simple data analysis example.\n",
    "\n",
    "### ED attendance data\n",
    "\n",
    "We will first use data held in the `minor_illness_ed_attends.csv`.  This is a synthetic time series dataset reporting the number of patients registered at GP surgery who attend ED each week.  The data are standardised to 10k of registered patients.\n",
    "\n",
    "#### Loading the dataset\n",
    "\n",
    "Let's first open the data and then construct some summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ebbd6150-3b8d-4e3a-8f45-24072ac4f9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74,)\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/minor_illness_ed_attends.csv'\n",
    "ed_data = np.loadtxt(file_name, skiprows=1, delimiter=',')\n",
    "print(ed_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a4f90-396f-4eec-90f4-6414582f0b9b",
   "metadata": {},
   "source": [
    "Here's a peak the first 5 elements in `ed_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ef8104da-4590-4cb9-8efb-81591357fae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.11927795, 3.49057545, 3.98922908, 2.36860477, 3.24124863])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b952022-b97d-4b09-85a0-a2afdee5fad7",
   "metadata": {},
   "source": [
    "#### Calculate summary statistics\n",
    "\n",
    "`numpy` makes it easy to calculate means, stdev and other summary statistics of an `ndarray`.  This typically have intuitive names which you can often guess. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fdbc6a46-d6b2-4a60-a659-a3ceb1d7efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.919482262743243\n",
      "0.7060975938853894\n"
     ]
    }
   ],
   "source": [
    "print(ed_data.mean())\n",
    "print(ed_data.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561832ed-d4c1-4443-8ec4-958c783a5e57",
   "metadata": {},
   "source": [
    "But it is always worth reading the docs.  For example to calculate an unbiased estimate of the sample standard deviation of a data set of length $n$ we should divide by $n - 1$.  In `numpy` we do this using the `ddof` (degree's of freedom) parameter of `std`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec924b-ac70-42ef-a26d-6b82eccae0fc",
   "metadata": {},
   "source": [
    "Here we will create a class to act as a convienient container for a dataset.  For convenience, we will override the `__str__` method so that we can easily print a summary of the dataset to the screen when calling `print`.\n",
    "\n",
    "The class will make use of the following `numpy` statistical procedures:\n",
    "\n",
    "* `min()` and `max()` to return the minimum and maximum value in array respectively\n",
    "* `np.percentile()` to calculate a percentile - here the median and upper / lower quartiles. \n",
    "* `np.histogram()` that bins data points and reports the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "b3f4f8ca-5b1d-4571-a8c3-b78579d407a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttendanceSummary:\n",
    "    '''\n",
    "    Simple container class Hold mean, stdev and 5/95 percentiles of ed data\n",
    "    '''\n",
    "    def __init__(self, data, name=None, decimal_places=2):\n",
    "        \"\"\"\n",
    "        Contructor method.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        data: numpy.ndarray \n",
    "            Vector containing data to analyse.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.dp = decimal_places\n",
    "        self.n = len(data)\n",
    "        self.mean = data.mean()\n",
    "        self.std = data.std(ddof=1)\n",
    "        self.min_attends = data.min()\n",
    "        self.max_attends = data.max() \n",
    "        \n",
    "        # percentiles: note that this is a np. call\n",
    "        self.lower_quartile = np.percentile(data, 25)\n",
    "        self.median = np.percentile(data, 50)\n",
    "        self.upper_quartile = np.percentile(data, 75)\n",
    "        self.iqr = self.upper_quartile - self.lower_quartile\n",
    "        \n",
    "        # frequency histogram (automatically binned)\n",
    "        self.freq, self.bins = np.histogram(data, density=False)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        to_print = f'\\nDataset: {self.name}' \\\n",
    "             + f'\\nMean:\\t{self.mean:.{self.dp}f}' \\\n",
    "             + f'\\nStdev:\\t{self.std:.{self.dp}f}' \\\n",
    "             + f'\\nMin:\\t{self.min_attends:.{self.dp}f}' \\\n",
    "             + f'\\nMax:\\t{self.max_attends:.{self.dp}f}' \\\n",
    "             + f'\\nMedian:\\t{self.median:.{self.dp}f}' \\\n",
    "             + f'\\nIQR:\\t{self.iqr:.{self.dp}f}' \\\n",
    "             + f'\\nn:\\t{self.n}'\n",
    "                    \n",
    "        return to_print\n",
    "    \n",
    "    def frequency_histogram(self):\n",
    "        print('x\\tf(x)')\n",
    "        for f, b in zip(self.freq, self.bins):\n",
    "            print(f'{b:.{self.dp}f}\\t{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ab826d4c-02d2-43f5-8491-29bc2eb5eb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Dataset: ED\n",
       "Mean:\t2.92\n",
       "Stdev:\t0.71\n",
       "Min:\t1.62\n",
       "Max:\t5.11\n",
       "Median:\t2.87\n",
       "IQR:\t1.09\n",
       "n:\t74"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = AttendanceSummary(ed_data, name=\"ED\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fc6bea85-c1d6-4911-aca4-b3ccd3934744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\tf(x)\n",
      "1.62\t5\n",
      "1.97\t9\n",
      "2.32\t14\n",
      "2.67\t16\n",
      "3.02\t11\n",
      "3.37\t6\n",
      "3.71\t10\n",
      "4.06\t2\n",
      "4.41\t0\n",
      "4.76\t1\n"
     ]
    }
   ],
   "source": [
    "x.frequency_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc292c-894d-40fd-8340-75e2cc13793d",
   "metadata": {},
   "source": [
    "Its not necessary to always use a class as I here, but it is useful if for example you want to compare samples or in the case of a time series period.\n",
    "\n",
    "In our ED data let's assume an intervention was put in place in week 10: GP surgeries were opened to patients over weekends. Let's summarise the results using descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b6c76191-67f9-4cfd-a0a5-30ee7fa7ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: before\n",
      "Mean:\t3.12\n",
      "Stdev:\t0.59\n",
      "Min:\t2.12\n",
      "Max:\t3.99\n",
      "Median:\t3.18\n",
      "IQR:\t0.81\n",
      "n:\t10\n",
      "\n",
      "Dataset: after\n",
      "Mean:\t2.89\n",
      "Stdev:\t0.73\n",
      "Min:\t1.62\n",
      "Max:\t5.11\n",
      "Median:\t2.87\n",
      "IQR:\t0.90\n",
      "n:\t64\n"
     ]
    }
   ],
   "source": [
    "week = 10  # the week the intervention begins\n",
    "before = AttendanceSummary(ed_data[:week], 'before')\n",
    "after = AttendanceSummary(ed_data[week:], 'after')\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1383f-6a5c-4a92-a3f8-9fe07c7fddc0",
   "metadata": {},
   "source": [
    "## Statistical procedures and n-dimensional arrays\n",
    "\n",
    "Generating statistics for matricies and n-dimensional arrays works in a similar manner to vectors.  To do this you need to specify an **axis** in the call to the statistical function e.g. `mean()`\n",
    "\n",
    "### Example: mean of matrix columns and rows\n",
    "\n",
    "Given `matrix` calculate the mean of the columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d13a6910-1d48-4d5f-aced-fdddab99c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[7.7, 4.3, 8.5],\n",
    "                   [6.9, 0.9, 9.7],\n",
    "                   [7.6, 7.8, 1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "714fca47-fd5d-4628-afeb-1b41f61e198e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.400000000000001"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d50411c8-8ff9-464a-b078-3641e8f2d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.333333333333333"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "bef2f532-ba43-426d-997c-6359d08f012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.466666666666666"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[:,2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "71752a14-0cbe-48cc-8e92-c7f7df8a0379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.4, 4.3, 6.5])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.mean(axis=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4bd44-a76a-49b1-88b0-eec28df0c689",
   "metadata": {},
   "source": [
    "## A note of caution: working with running statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4bf52-9ebf-446e-ade4-4decdb820cd4",
   "metadata": {},
   "source": [
    "In many computational modelling procedures you will need an estimate of statistics as the code executes. For example, you may need to track a mean or a standard deviation of a performance measure in a multi-stage algorithm or as a simulation model of a healthcare system executes. \n",
    "\n",
    "As we have seen `numpy` provides highly efficient functions for calculating a mean or standard deviation based on data held in an array.  I'm always tempted to make use of these built in procedures. They are indeed fast and incredibly easy to use.  The downside is that you waste computation via repeated iteration over an array.  The other option, that requires more careful thought (due to floating point issues), is a running estimate of your statistics.  In general, I've implemented such procedures  in standard python.  Let's look at an example where we compare recalculation using a `numpy` function with a running (sometimes called an 'online') calculation of the mean and standard deviation in standard python.\n",
    "\n",
    "We will first refactor `AttendanceSummary` to an `OnlineSummary` class to include an `update()` function.  It will accept a `np.ndarray` that recalculates the **sample** mean and standard deviation using a `numpy` on the full data set.  The function `test_complete_recalculation` iteratively calls `update` using more data each time.  For simplicities sake we will reuse the data contained within `ed_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "377eac13-edbd-418d-9434-4467aa23c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineSummary:\n",
    "    \n",
    "    def __init__(self, data=None, decimal_places=2):\n",
    "        \"\"\"\n",
    "        Track online statistics of mean and standard deviation.\n",
    "\n",
    "        Params:\n",
    "        -------\n",
    "        data: np.ndarray, optional (default = None) \n",
    "            Contains an initial data sample.\n",
    "            \n",
    "        decimal_places: int, optional (default=2)\n",
    "            Summary decimal places.\n",
    "        \"\"\"\n",
    "        if isinstance(data, np.ndarray):\n",
    "            self.n = len(data)\n",
    "            self.mean = data.mean()\n",
    "            self.std = data.std(ddof=1)\n",
    "        else:\n",
    "            self.n = 0\n",
    "            self.mean = None\n",
    "            self.std = None\n",
    "            \n",
    "        self.dp = decimal_places\n",
    "        \n",
    "    def update(self, data):\n",
    "        '''\n",
    "        Update the mean and standard deviation using complete recalculation.\n",
    "        \n",
    "        Params:\n",
    "        ------\n",
    "        data: np.ndarray\n",
    "            Vector of data\n",
    "        '''\n",
    "        self.n = len(data)\n",
    "        \n",
    "        # update the mean and std. Easy!\n",
    "        self.mean = data.mean()\n",
    "        self.std = data.std(ddof=1)\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        to_print = f'Mean:\\t{self.mean:.{self.dp}f}' \\\n",
    "             + f'\\nStdev:\\t{self.std:.{self.dp}f}' \\\n",
    "             + f'\\nn:\\t{self.n}' \\\n",
    "        \n",
    "        return to_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "80ea49a4-20b5-4595-8bca-7dacc46a90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_complete_recalculation(data, start=1):\n",
    "    summary = OnlineSummary(data[:start])\n",
    "\n",
    "    for i in range(start, len(data)+1):\n",
    "        summary.update(data[:i])\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "93d5d3eb-0878-4b09-a0f8-f913136b0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\t2.92\n",
      "Stdev:\t0.71\n",
      "n:\t74\n"
     ]
    }
   ],
   "source": [
    "summary = test_complete_recalculation(ed_data)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "77b7bde7-a5fd-4f60-a8e3-e0aac6918729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 ms ± 13 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit summary = test_complete_recalculation(ed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ad43a-eec9-4783-b933-3b0c6ff87545",
   "metadata": {},
   "source": [
    "You should find the `numpy` implementation fairly efficient clocking in at around 1.5ms on average. But can we do better in standard python by computing an online mean and standard deviation?\n",
    "\n",
    "To do this we will use **Welford's algorithm** for computing a running sample mean and standard deviation.  This is a robust, accuate and old(ish) approach (1960s) that I first read about in Donald Knuth's *art of computer programming vol 2.* (just to be clear I learnt how to do this in 2008 not 1960!).  To implement it we need to refactor `update`.  Note that we will need a fair bit more code than our simple `numpy` solution.\n",
    "\n",
    "The algorithm is given in a recursive format.  For our purposes here, you can just think of that as tracking the mean and standard deviation as attributes of a class that we iteratively update with a new $x$. \n",
    "\n",
    "The first thing you need to do is handle the first observation encountered. \n",
    "\n",
    "$$M_1 = x_1$$\n",
    "$$S_1 = 0$$\n",
    "\n",
    "Then on each subsequent call you update $M$ and $S$ making use of the previous values.  Note that $M$ has a relatively simple interpretation: its the sample mean. However, $S$ is not the standard deviation.  Its actually the sum of squares of differences from the current mean.  We will look at how to update that first and then I'll show you the equation for converting to the standard deviation.\n",
    "\n",
    "$$M_n = M_{n-1} + \\dfrac{x_n - M_{n-1}}{n}$$\n",
    "\n",
    "\n",
    "$$S_n = S_{n-1} + \\left[(x_n - M_{n-1}) \\times (x_n - M_n)\\right]$$\n",
    "\n",
    "If the equations are confusing you can think of $M_n$ as the `updated_mean` and $M_{n-1}$ as the `previous_mean`.\n",
    "\n",
    "Once the update is complete it is then relatively trivial to calculate the standard deviation $\\sigma_n$.  Note that we don't necessarily need to track the standard deviation just $S_n$.  We can inexpensively calculate $\\sigma_n$ when it is needed.  \n",
    "\n",
    "$$\\sigma_n = \\sqrt{\\dfrac{S_n}{n-1}}$$\n",
    "\n",
    "The code listing below modifies `OnlineSummary` to make use of Welford's algorithm. Note that `std` is now a property that calculates the standard deviation on the fly using $S_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "de102fa2-28e8-457b-bddd-766a9f9671b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineSummary:\n",
    "    \n",
    "    def __init__(self, data=None, decimal_places=2):\n",
    "        \"\"\"\n",
    "        Returns mean, stdev and 5/95 percentiles of ed data\n",
    "\n",
    "        Params:\n",
    "        -------\n",
    "        data: np.ndarray, optional (default = None) \n",
    "            Contains an initial data sample.\n",
    "            \n",
    "        decimal_places: int, optional (default=2)\n",
    "            Summary decimal places.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n = 0\n",
    "        self.mean = None\n",
    "        self._sq = None\n",
    "        \n",
    "        if isinstance(data, np.ndarray):\n",
    "            for x in data:\n",
    "                self.update(x)\n",
    "            \n",
    "        self.dp = decimal_places\n",
    "    \n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self._sq / (self.n - 1)\n",
    "    \n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(self.variance)\n",
    "    \n",
    "    def update(self, x):\n",
    "        '''\n",
    "        Running update of mean and variance implemented using Welford's \n",
    "        algorithm (1962).\n",
    "        \n",
    "        See Knuth. D `The Art of Computer Programming` Vol 2. 2nd ed. Page 216.\n",
    "        \n",
    "        Params:\n",
    "        ------\n",
    "        x: float\n",
    "            A new observation\n",
    "        '''\n",
    "        self.n += 1\n",
    "        \n",
    "        # we need to do more work ourselves for online stats!\n",
    "        \n",
    "        # init values\n",
    "        if self.n == 1:\n",
    "            self.mean = x\n",
    "            self._sq = 0\n",
    "        else:\n",
    "            # compute the updated mean\n",
    "            updated_mean = self.mean + ((x - self.mean) / self.n)\n",
    "        \n",
    "            # update the sum of squares \n",
    "            self._sq += (x - self.mean) * (x - updated_mean)\n",
    "            \n",
    "            # update the tracked mean\n",
    "            self.mean = updated_mean\n",
    "    \n",
    "    def __str__(self):\n",
    "        to_print = f'Mean:\\t{self.mean:.{self.dp}f}' \\\n",
    "             + f'\\nStdev:\\t{self.std:.{self.dp}f}' \\\n",
    "             + f'\\nn:\\t{self.n}' \\\n",
    "        \n",
    "        return to_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "79de9616-0752-47c2-8679-2d86469aced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_online_calculation(data, start=1):\n",
    "    summary = OnlineSummary()\n",
    "\n",
    "    for observation in data:\n",
    "        summary.update(observation)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f8aa161f-6314-403b-8077-b116dc5fa003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\t2.92\n",
      "Stdev:\t0.71\n",
      "n:\t74\n"
     ]
    }
   ],
   "source": [
    "summary = test_online_calculation(ed_data)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "60b784d3-2696-4fca-84ff-b43732f7ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.8 µs ± 597 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit summary = test_online_calculation(ed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503f85a-d621-4df0-b84b-c9742335bc89",
   "metadata": {},
   "source": [
    "Crickey nothing beats a good algorithm! You should find that you are now working in microseconds (µs) as opposed to milliseconds. 1µs = 1000ms. On my machine the `test_online_calculation` executes in ~45 µs on average while `test_complete_recalculation` takes ~1500 µs. So we are finding a speed up of ~97%. That gap will continue to grow as the number of samples $n$ increases.  The result is explained because our second implementation has a constant time for execution (and constant number of computational steps) while the time complexity of the `numpy` call depends on the size of the array. That's a lesson well worth remembering when developing code for scientific applications requiring performant code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
