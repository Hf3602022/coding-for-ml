{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "circular-basis",
   "metadata": {},
   "source": [
    "# Arrays versus lists\n",
    "\n",
    "Before we get too far into how to use `numpy` for health data science I want to spend a bit of time illustrating the importance of the `numpy.ndarray`. So far we have used standard python data structures such as a  `List` for holding 'arrays' of data. As a reminder lists are easy to use and very flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tested-giant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[999, 3, 9.5, 'eggs', ['sub list', 3], <class 'int'>, 'foo']\n"
     ]
    }
   ],
   "source": [
    "my_list = ['spam', 3, 9.5, 'eggs', ['sub list', 3], int]\n",
    "my_list.append('foo')\n",
    "my_list[0] = 999\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-karma",
   "metadata": {},
   "source": [
    "The flexibility of a `List` means that they are not well suited to scientific computing. `numpy` provides optimised efficient code for managing data (typically quantitative data).  A favourite phrase of mine that I heard used to describe `numpy` is that its **closer to the metal**.  \n",
    "\n",
    "> For scientific computing you **should** use numpy instead of Python Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-australian",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "It is fairly standard to import `numpy` and give it the alias `np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accessory-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-rubber",
   "metadata": {},
   "source": [
    "## Performance differences\n",
    "\n",
    "The fundamental building block of numpy is the `numpy.ndarray`.  This standard for **n-dimensional** array. Let's create one manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "super-baseball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]; 4\n"
     ]
    }
   ],
   "source": [
    "my_arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "print(my_arr, end='; ')  # print full array\n",
    "print(my_arr[3])  # access an zero indexed element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-police",
   "metadata": {},
   "source": [
    "I know what you are thinking again!  That looks and behaves just like a python `list`!  If you take nothing else away from this section remember that **an array is NOTHING like a list!** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-algebra",
   "metadata": {},
   "source": [
    "Let's compare the speed to lists and array by summing 1 million values.  First let's create the data structures and values in memory.\n",
    "\n",
    "> The `np.arange` function works in a similar way to `range` (caveat range is a generator).  It is creating a sequence of numeric values of a given datatype.  For example, `np.arange(5)` is equivalent to `np.array([0, 1, 2, 3, 4])`.  We will look at ways to create arrays in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "square-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_list = list(range(1_000_000))\n",
    "numpy_array = np.arange(1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-thinking",
   "metadata": {},
   "source": [
    "Now let's compare the average time of computation using the ipython magic `%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blocked-unemployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51 ms ± 195 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum(python_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "executed-disclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 µs ± 2.41 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sum(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-onion",
   "metadata": {},
   "source": [
    "> If you are struggling to understand the time difference reported by `%timeit` I can assure you that it is substantial - an order of magnitude in fact.  The python list is taking milliseconds per loop while the array is taking micro seconds. 1 ms = 1000 µs.  This improvement in performance has implications for your scientific coding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-spain",
   "metadata": {},
   "source": [
    "## Difference in usage and behaviour\n",
    "\n",
    "For someone new to `numpy` it is helpful to remember the following:\n",
    "\n",
    "* Array size and datatype are declared **upfront** and data are stored efficiently in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-particle",
   "metadata": {},
   "source": [
    "Let's test this statement and try few operations on a `ndarray` that you would routinely use with a `list`.  First let's see if we can dynamically add a new element to the array (change its size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "executed-theorem",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d7ebd5f93b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "my_arr.append(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-martin",
   "metadata": {},
   "source": [
    "Due to the way `numpy` works, the size of an array is **fixed**.  There is no direct append method (although as we will see later there is a way with associated performance penalty).\n",
    "\n",
    "Now let's look at the datatype difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imperial-robinson",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Zero'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e9bed3bd39fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Zero'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Zero'"
     ]
    }
   ],
   "source": [
    "my_arr[0] = 'Zero'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-occupation",
   "metadata": {},
   "source": [
    "Here `numpy` raised a `ValueError`.  This was because `my_arr` can only contain integer values. Let's see what happens if we try to overwrite element zero with a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "social-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99  2  3  4  5  6]\n"
     ]
    }
   ],
   "source": [
    "my_arr[0] = 99.999999\n",
    "print(my_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-aruba",
   "metadata": {},
   "source": [
    "This time there was no `ValueError`, but a more subtle error was introduced.  The data was truncated to an integer.  This is because memory is carefully managed in `numpy` again for efficieny.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
